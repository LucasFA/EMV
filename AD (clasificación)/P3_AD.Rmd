---
title: "Análisis discriminante con R"
author: José L. Romero (adapatación del material de [Joaquín Amat Rodrigo](https://www.cienciadedatos.net/documentos/28_linear_discriminant_analysis_lda_y_quadratic_discriminant_analysis_qda)).
date: "`r Sys.Date()`"
output:
  html_document: 
    
    toc: true
    toc_depth: 5
    number_sections: false
    toc_float: 
      collapsed: false
      smooth_scroll: false
  pdf_document: default
---
<style>
.math {
  font-size: 8.25pt;options(encoding = 'UTF-8')
}
</style>

<div style="text-align: justify">


En esta práctica se realiza un ejemplo de **análisis discriminante lineal y cuadrádtico**.


  
## 1. Análisis discriminante lineal

Un equipo de biólogos quiere generar un modelo estadístico que permita identificar a que especie (a ó b) pertenece un determinado insecto. 

Como **datos de entrenamiento** se han medido tres variables (**longitud de las patas, diámetro del abdomen y diámetro del órgano sexual** en milímetros) en 10 individuos de cada una de las dos especies.
```{r}
especie <- c("a", "a", "a", "a", "a", "a", "a", "a", "a", "a", "b", "b", "b", "b", "b", "b", "b", "b", "b", "b")
pata <- c(191, 185, 200, 173, 171, 160, 188, 186, 174, 163, 186, 211, 201, 242, 184, 211, 217, 223, 208, 199)
abdomen <- c(131, 134, 137, 127, 128, 118, 134, 129, 131, 115, 107, 122, 144, 131, 108, 118, 122, 127, 125, 124)
organo_sexual <- c(53, 50, 52, 50, 49, 47, 54, 51, 52, 47, 49, 49, 47, 54, 43, 51, 49, 51, 50, 46)

datos <- data.frame(especie, pata, abdomen, organo_sexual)
datos$especie <- as.factor(datos$especie)
```
### 1.1. Exploración gráfica de los datos

En primer lugar exploramos como de bien (o mal) clasifica en las especies **cada una de las variables** medidas de forma independiente.
```{r}
library(ggplot2)
library(ggpubr)

p1 <- ggplot(data = datos, aes(x = pata, fill = especie)) +
  geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = datos, aes(x = abdomen, fill = especie)) +
  geom_histogram(position = "identity", alpha = 0.5)
p3 <- ggplot(data = datos, aes(x = organo_sexual, fill = especie)) +
  geom_histogram(position = "identity", alpha = 0.5)

ggarrange(p1, p2, p3, nrow = 3, common.legend = TRUE)
```

En este sentido, parece que la variable **longitud de la pata** es la que mejor diferencia entre especies (menor solapamiento).

A continuación, exploramos qué **pares de variables** separan mejor entre especies.

```{r}
pairs(
  x = datos[, c("pata", "abdomen", "organo_sexual")],
  col = c("firebrick", "green3")[datos$especie], pch = 19
)
```

La combinación de variables **abdomen-pata** y **pata-organo_sexual** parecen separar adecuadamente entre especies.

Finalmente, exploramos si las **tres variables** juntas diferencian adecuadamente entre las dos especies.

```{r}
library(scatterplot3d)
scatterplot3d(datos$pata, datos$abdomen, datos$organo_sexual,
  color = c("firebrick", "green3")[datos$especie], pch = 19,
  grid = TRUE, xlab = "pata", ylab = "abdomen",
  zlab = "organo sexual", angle = 65, cex.axis = 0.6
)
legend("topleft",
  bty = "n", cex = 0.8,
  title = "Especie",
  c("a", "b"), fill = c("firebrick", "green3")
)
```

Efectivamente, las tres variables de forma simultánea separan perfectamente las dos especies en el espacio tridimensional generado.

### 1.2. Normalidad univariante y multivariante

A continuación hacemos una exploración gráfica de la **normalidad** de las **distribuciones individuales** de nuestros predictores representando los **histogramas** y los **gráficos qqplots**.

**Distribuciones individuales**
```{r}
# Representación mediante Histograma de cada variable para cada especie
par(mfcol = c(2, 3))
for (k in 2:4) {
  j0 <- names(datos)[k]
  # br0 <- seq(min(datos[, k]), max(datos[, k]), le = 11)
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$especie)[i]
    x <- datos[datos$especie == i0, j0]
    hist(x, proba = T, col = grey(0.8), main = paste("especie", i0), xlab = j0)
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}
```

**Gráficos qqplots**
```{r}
# Representación de cuantiles normales de cada variable para cada especie
par(mfrow = c(2, 3))
for (k in 2:4) {
  j0 <- names(datos)[k]
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$especie)[i]
    x <- datos[datos$especie == i0, j0]
    qqnorm(x, main = paste("especie", i0, j0), pch = 19, col = i + 1)
    qqline(x)
  }
}
```

Este análisis exploratorio puede darnos una idea de la posible distribución normal de las variables univariadas, pero siempre es mejor hacer los respectivos test de normalidad.

**Test de normalidad univariantes (Shapiro-Wilk)**
```{r}
library(reshape2)
library(knitr)
library(dplyr)
datos_tidy <- melt(datos, value.name = "valor")
aggregate(
  formula = valor ~ especie + variable, data = datos_tidy,
  FUN = function(x) {
    shapiro.test(x)$p.value
  }
)
```

No se encuentran evidencias de falta de normalidad univariante.

**Test de normalidad multivariante (Mardia, Henze-Zirkler y Royston)**

El paquete **MVN** contiene funciones que permiten realizar los tres test que se utilizan habitualmente para **contrastar la normalidad multivariante**.
Esta normalidad multivariante puede verse afectada por la presencia de outliers. En este paquete también encontramos **funciones para el análisis de outliers**.

```{r}
# El paquete solo se instala una vez para evitar errores de ejecución puesto que está en nuestro repositorio local.
# install.packages("MVN")
library(MVN)
outliers <- mvn(data = datos[, -1], mvnTest = "hz", multivariateOutlierMethod = "quan")
```

Se detectan 5 outliers en las observaciones 2, 11, 13, 16 y 20. Sin embargo ninguno de los dos test realizados a continuación encuentran evidencias al 5% de significación de falta de normalidad multivariante.

```{r}
royston_test <- mvn(data = datos[, -1], mvnTest = "royston", multivariatePlot = "qq")

royston_test$multivariateNormality

hz_test <- mvn(data = datos[, -1], mvnTest = "hz")
hz_test$multivariateNormality
```

### 1.3. Homogeneidad de la varianza

* Cuando hay **un solo predictor** el test más recomendable es el **test de Barttlet**, ya utilizado en prácticas anteriores.
* Cuando se emplean **múltiples predictores**, se tiene que contrastar que la matriz de covarianzas es constante en todos los grupos. En este caso es también recomendable comprobar la homogeneidad de la varianza para cada predictor a nivel individual. El test más recomendable es el **test de Box M**, que es una extensión del de Barttlet para escenarios multivariantes. Hay que tener en cuenta que es **muy sensible a que los datos efectivamente se distribuyan según una normal multivariante**. Por este motivo se recomienda utilizar una significación (p-value) <0.001.

La **hipóstesis nula** a contrastar es la de **igualdad de matrices de covarianzas** en todos los grupos.

```{r}
# El paquete solo se instala una vez para evitar errores de ejecución puesto que está en nuestro repositorio local.
# install.packages("biotools")
library(biotools)
boxM(data = datos[, 2:4], grouping = datos[, 1])
```

En este caso no rechazamos la hipótesis nula ya que **p-value = 0.132 > 0.001** y por tanto **asumimos la homogeneidad de varianzas**.
Es importante recordar que para que esta **conclusión sea fiable** debe darse el supuesto de **normalidad multivariante**.

### 1.4. Función discriminante

La función **lda** del paquete **MASS** realiza la clasificación.

```{r}
modelo_lda <- lda(formula = especie ~ pata + abdomen + organo_sexual, data = datos)
modelo_lda
```

La salida de este objeto, nos muestra las **probabilidades a priori** de cada grupo, en este caso 0.5 para cada especie (10/20), las **medias de cada regresor por grupo** y los **coeficientes del modelo de clasificación discrimiante lineal**, que en este caso tendría la forma: 

*odds = 0.13225339pata - 0.07941509abdomen - 0.52655608organo_sexual*

Una vez construido el clasificador podemos clasificar nuevos datos en función de sus medidas sin más que llamar a la función **predict**. Por ejemplo, un nuevo espécimen cuyas medidas sean: pata = 194, abdomen = 124, organo_sexual = 49.

```{r}
nuevas_observaciones <- data.frame(pata = 194, abdomen = 124, organo_sexual = 49)
predict(object = modelo_lda, newdata = nuevas_observaciones)
```

Según la función discriminante, la probabilidad a posteriori de que el especimen sea de la especie **b** es del 94.2% mientras la de que sea de la especie **a** es tan solo del 5.8%. Por tanto este especimen sería clasificado en la especie **b**. Aunque tomando como *cut-point* **p = 0.5** dado que la función discriminante toma el valor **0.5419421** también invitaría a clasificarlo en la especie **b**.

### 1.5. Validación cruzada
La función **confusionmatrix** del paquete **biotools** realiza una validación cruzada del modelo de clasificación.

```{r}
pred <- predict(modelo_lda, dimen = 1)
confusionmatrix(datos$especie, pred$class)

# Porcentaje de errores de clasificación
trainig_error <- mean(datos$especie != pred$class) * 100
paste("trainig_error=", trainig_error, "%")
```

En este caso el porcentaje de aciertos es del 100% (no es lo habitual).

### 1.6. Visualización de las clasificaciones

La función **partimat** del paquete **klaR** permite representar los **límites de clasificación** de un modelo discriminante lineal o cuadrático para cada par de predictores. Cada color representa una región de clasificación acorde al modelo, **se muestra el centroide** de cada región y el **valor real de las observaciones**.

```{r}
# El paquete solo se instala una vez para evitar errores de ejecución puesto que está en nuestro repositorio local.
# install.packages("klaR")
library(klaR)
partimat(especie ~ pata + abdomen + organo_sexual,
  data = datos, method = "lda", prec = 200,
  image.colors = c("darkgoldenrod1", "snow2"),
  col.mean = "firebrick", nplots.vert = 1, nplots.hor = 3
)
```

A diferencia de la clasificación con  las tres medidas que tiene un error del 0%, al considerar la clasificación según cada par de variables, se cometen errores mayores, aunque como se intuía desde el principio el tándem abdomen-pata y organo_sexual-pata cometen poco error en la clasificación (5%) mientras el error con el tándem abdomen-organo_sexual se dispara al 30%.




################################################################################

## 2. Análisis discriminante cuadrático

En este ejemplo se ilustra el análisis discriminante cuadrático mediante un conjunto de **datos de entrenamiento simulados**.

```{r}
set.seed(8558)
grupoA_x <- seq(from = -3, to = 4, length.out = 100)
grupoA_y <- 6 + 0.15 * grupoA_x - 0.3 * grupoA_x^2 + rnorm(100, sd = 1)
grupoA <- data.frame(variable_z = grupoA_x, variable_w = grupoA_y, grupo = "A")

grupoB_x <- rnorm(n = 100, mean = 0.5, sd = 0.8)
grupoB_y <- rnorm(n = 100, mean = 2, sd = 0.8)
grupoB <- data.frame(variable_z = grupoB_x, variable_w = grupoB_y, grupo = "B")

datos <- rbind(grupoA, grupoB)
datos$grupo <- as.factor(datos$grupo)

plot(datos[, 1:2], col = datos$grupo, pch = 19)
```

### 2.1. Exploración gráfica de los datos

En primer lugar exploramos como de bien o mal clasifica en las especies **cada una de las variables** medidas de forma independiente.
```{r}
p1 <- ggplot(data = datos, aes(x = variable_z, fill = grupo)) +
  geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = datos, aes(x = variable_w, fill = grupo)) +
  geom_histogram(position = "identity", alpha = 0.5)
ggarrange(p1, p2, nrow = 2, common.legend = TRUE, legend = "bottom")
```

En este sentido, parece que la  **variable_w** es la que mejor diferencia entre grupos (menor solapamiento).


### 2.2. Normalidad univariante y multivariante

A continuación hacemos una exploración gráfica de la **normalidad** de las **distribuciones individuales** de nuestros predictores representando los **histogramas** y los **gráficos qqplots**.

**Distribuciones individuales**
```{r}
# Representación mediante histograma de cada variable para cada grupo
par(mfcol = c(2, 2))
for (k in 1:2) {
  j0 <- names(datos)[k]
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$grupo)[i]
    x <- datos[datos$grupo == i0, j0]
    hist(x,
      proba = T, col = grey(0.8), main = paste("grupo", i0),
      xlab = j0
    )
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}
```

**Gráficos qqplots**
```{r}
# representación de cuantiles normales de cada variable para cada grupo
par(mfcol = c(2, 2))
for (k in 1:2) {
  j0 <- names(datos)[k]
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$grupo)[i]
    x <- datos[datos$grupo == i0, j0]
    qqnorm(x, main = paste(i0, j0), pch = 19, col = i + 1)
    qqline(x)
  }
}
```

Este análisis exploratorio puede darnos una idea de la posible distribución normal de las variables univariadas, pero siempre es mejor hacer los respectivos test de normalidad.

**Test de normalidad univariantes (Shapiro-Wilk)**
```{r}
# Contraste de normalidad Shapiro-Wilk para cada variable en cada grupo
library(reshape2)
datos_tidy <- melt(datos, value.name = "valor")
library(dplyr)
datos_tidy %>%
  group_by(grupo, variable) %>%
  summarise(p_value_Shapiro.test = round(shapiro.test(valor)$p.value, 5))
```

La variable **z** no se distribuye según una ley normal para el **grupo A**.

**Test de normalidad multivariante (Mardia, Henze-Zirkler y Royston)**

El paquete **MVN** contiene funciones que permiten realizar los tres test que se utilizan habitualmente para **contrastar la normalidad multivariante**.
Esta normalidad multivariante puede verse afectada por la presencia de outliers. En este paquete también encontramos **funciones para el análisis de outliers**.

```{r}
# El paquete solo se instala una vez para evitar errores de ejecución puesto que está en nuestro repositorio local.
# install.packages("MVN")
library(MVN)
outliers <- mvn(data = datos[, -3], mvnTest = "hz", multivariateOutlierMethod = "quan")
```

Se detectan 6 outliers en las observaciones 39, 49, 51, 65, 66 y 85. Los dos test realizados a continuación encuentran evidencias, al 5% de significación, de falta de normalidad multivariante. 

Si bien es cierto que **no se cumple el supuesto de normalidad multivariante**, el análisis **discriminante cuadrático tiene cierta robustez** en este caso, aunque conviene tenerlo en cuenta en las conclusiones del análisis.

```{r}
royston_test <- mvn(data = datos[, -3], mvnTest = "royston", multivariatePlot = "qq")
royston_test$multivariateNormality

hz_test <- mvn(data = datos[, -3], mvnTest = "hz")
hz_test$multivariateNormality
```

### 2.3. Homogeneidad de la varianza

* Cuando hay **un solo predictor** el test más recomendable es el **test de Barttlet**, ya utilizado en prácticas anteriores.
* Cuando se emplean **múltiples predictores**, se tiene que contrastar que la matriz de covarianzas es constante en todos los grupos. En este caso es también recomendable comprobar la homogeneidad de la varianza para cada predictor a nivel individual. El test más recomendable es el **test de Box M**, que es una extensión del de Barttlet para escenarios multivariantes. Hay que tener en cuenta que es **muy sensible a que los datos efectivamente se distribuyan según una normal multivariante**. Por este motivo se recomienda utilizar una significación (p-value) <0.001.

La **hipóstesis nula** a contrastar es la de **igualdad de matrices de covarianzas** en todos los grupos.

```{r}
# El paquete solo se instala una vez para evitar errores de ejecución puesto que está en nuestro repositorio local.
# install.packages("biotools")
library(biotools)
boxM(data = datos[, -3], grouping = datos[, 3])
```

En este caso rechazamos la hipótesis nula ya que **p-value < 0.001** y por tanto **asumimos la NO homogeneidad de varianzas**.
Es importante recordar que para que esta **conclusión sea fiable** debe darse el supuesto de **normalidad multivariante**, que en este caso no se da. De hecho cuando no existe distribución normal multivariante este test siempre sale significativo y por tanto no es fiable.

### 2.4. Función discriminante

La función **qda** del paquete **MASS** realiza la clasificación.

```{r}
library(MASS)
modelo_qda <- qda(grupo ~ variable_z + variable_w, data = datos)
modelo_qda
```

La salida de este objeto, nos muestra las **probabilidades a priori** de cada grupo, en este caso 0.5 y las **medias de cada regresor por grupo**.

Una vez construido el clasificador podemos clasificar nuevos datos en función de sus medidas sin más que llamar a la función **predict**. Por ejemplo, un nuevo registro cuyos valores sean: variable_z = 5, variable_w = 3.

```{r}
nuevas_observaciones <- data.frame(variable_z = 5, variable_w = 3)
predict(object = modelo_qda, newdata = nuevas_observaciones)
```

Según la función discriminante, la probabilidad a posteriori de que el nuevo registro esté en la **variable_z** es del 99,9%% mientras la de que esté en la **variable_w** es inferior al 0.1%. Por tanto este dato sería clasificado en la **variable_z**.

### 2.5. Validación cruzada
La función **confusionmatrix** del paquete **biotools** realiza una validación cruzada del modelo de clasificación.

```{r}
pred <- predict(modelo_qda, dimen = 1)
confusionmatrix(datos$grupo, pred$class)

# Porcentaje de errores de clasificación
trainig_error <- mean(datos$grupo != pred$class) * 100
paste("trainig_error=", trainig_error, "%")
```

En este caso el porcentaje de aciertos es del 95%.

### 2.6. Visualización de las clasificaciones

La función **partimat** del paquete **klaR** permite representar los **límites de clasificación** de un modelo discriminante lineal o cuadrático para cada par de predictores. Cada color representa una región de clasificación acorde al modelo, **se muestra el centroide** de cada región y el **valor real de las observaciones**.

```{r}
# El paquete solo se instala una vez para evitar errores de ejecución puesto que está en nuestro repositorio local.
# install.packages("klaR")
library(klaR)
partimat(
  formula = grupo ~ variable_z + variable_w, data = datos,
  method = "qda", prec = 400,
  image.colors = c("darkgoldenrod1", "skyblue2"),
  col.mean = "firebrick"
)
```

### 3. Comparación de los métodos de análisis discriminante lineal(LDA) y cuadrático (QDA)

Qué clasificador es más adecuado depende de las implicaciones que tiene el asumir que todos los grupos comparten una matriz de covarianza común ya que puede producirse un sesgo en las clasificaciones o producir varianzas altas.

* LDA produce **límites de decisión lineales**, lo que se traduce en **menor flexibilidad** y por lo tanto menor problema de varianza.
* QDA produce **límites cuadráticos** y por lo tanto curvos, lo que aporta mayor flexibilidad permitiendo ajustarse mejor a los datos, menor sesgo pero mayor riesgo de varianza.
* En términos generales, **LDA tiende a conseguir mejores clasificaciones que QDA cuando hay pocas observaciones con las que entrenar al modelo**, escenario en el que evitar la varianza es crucial.
* Si se dispone de una **gran cantidad de observaciones de entrenamiento** o si no es asumible que existe una matriz de covarianza común entre clases, **QDA es más adecuado**.
* Si se dispone de **p predictores**, calcular una matriz de **covarianza común requiere estimar p(p+1)/2 parámetros**, mientras que **calcular una matriz diferente para cada grupo requiere de Kp(p+1)/2** (K es el número de grupos de la variable respuesta). Para valores de **p muy altos**, la elección del método puede estar limitada por la **capacidad computacional**.
