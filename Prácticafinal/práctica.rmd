---
title: "Práctica final"
author: "Agnese, Lucas Fehlau Arbulu"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: true
    toc_depth: 3
    number_sections: false
    toc_float: 
      collapsed: false
      smooth_scroll: false
  pdf_document:
    keep_tex: true
---
# Read the data
```{r ReadData}
diabetes_full <- read.csv("diabetes.csv", stringsAsFactors = TRUE)
head(diabetes_full)
```

# Univariate explorative analysis
The variables we are dealing with are described as below: 

+ Number of times pregnant
+ Plasma glucose concentration a 2 hours in an oral glucose tolerance test
+ Diastolic blood pressure (mm Hg)
+ Triceps skin fold thickness (mm)
+ 2-Hour serum insulin (mu U/ml)
+ Body mass index (weight in kg/(height in m)^2)
+ Diabetes pedigree function
+ Age (years)
+ Class variable (0 or 1 for tested_positive or tested_negative)

We are not interesed in the number of pregnancy, so we will omit this variable. The response variable will be `class`, which tells us if a patient shows signs of diabetes according to World Health Organization criteria (i.e., if the 2 hour post-load plasma glucose was at least $200$ mg/dl at any survey examination or if found during routine medical care). A sample of $768$ females of Pima Indian heritage, a population that lives near Phoenix, Arizona, USA, have been considered, where the girls are at least 21 years old.

```{r}
# Remove the first column from the dataset
diabetes <- diabetes_full[, -1]
head(diabetes)
summary(diabetes)
```
In this dataset, all the missing values have been substituted by the number $0$. Since, for example, it doesn't make any sense to consider a $0$ mm thickness of the triceps skin fold of a girl or a zero diastolic blood pressure, we detect this "kind of" missing values and we substitute them with the mean of the considered variable. 
```{r}
# Replace zeros of all columns with NA, so that we can use the functions to
# detect missing values showed in class
diabetes[diabetes == 0] <- NA
head(diabetes)


### ----- i) -----
# Percentage of missing values in each column
percNA <- (colMeans(is.na(diabetes))) * 100
percNA

# Columns skin and insu have more then 5%


# Function to detect missing values and replace them with the mean of that
# variable
not_available <- function(data) {
  data[is.na(data)] <- mean(data, na.rm = TRUE)
  data
}

# Replace NA with the mean of that variable
df <- data.frame(lapply(diabetes[1:7], not_available))
head(df)

# Data without NA. The NA are replaced by the mean of each column.
new_diab <- cbind(df, diabetes[8])
head(new_diab)


### ------- ii) ----------
# Student t-test for homogenity
t.test(new_diab$age, new_diab$skin)
t.test(new_diab$pres, new_diab$mass)
```
<!-- TODO: what is the homogeneity test for? -->

## Análisis exploratorio multivariante

Eliminamos la variable respuesta categórica
```{r}
diab_no_output <- subset(new_diab, select = -class)
```
<!-- a) -->
Y comprobamos si tiene sentido aplicar PCA con el test de Bartlett
```{r}
cor(diab_no_output)
library(psych)
data_normalised <- scale(diab_no_output)
cortest.bartlett(cor(data_normalised))
```
<!-- b hecho? TODO -->
<!-- c Done in the previous  -->


<!-- d) -->
Actual PCA
```{r}
PCA <- prcomp(diab_no_output, scale = TRUE, center = TRUE)

PCA$rotation

plot(cumsum(PCA$sdev^2) / (sum(PCA$sdev^2)), type = "l") # check this
summary(PCA)
```
### Choosing the number of components
We need the function `fviz_screeplot` from the `factoextra` package.

```{r}
library(factoextra)
```

#### Elbow method
```{r}
fviz_screeplot(PCA, addlabels = TRUE)
```
Suggests 3 components
#### Mean variace method
```{r}
PCA$sdev
mean(PCA$sdev^2)
```
Also suggests 3 components.

<!-- TODO: where does this go? It doesn't seem to appear in the guide -->
### Visualization of principal components
```{r}
fviz_pca_var(PCA,
        repel = TRUE, col.var = "cos2",
        legend.title = "Distancia"
) + theme_bw()
```

```{r}
fviz_pca_var(PCA,
        axes = c(1, 3),
        repel = TRUE, col.var = "cos2",
        legend.title = "Distancia"
) + theme_bw()
```

<!-- TODO?: interpretation -->

<!-- e) -->
## Factor analysis
### Preconditions
We saw in our previous analysis of correlations for PCA that the data 

```{r}
poly_cor <- polycor::hetcor(diab_no_output)$correlations
ggcorrplot::ggcorrplot(poly_cor, type = "lower", hc.order = T)
```

```{r}
corrplot::corrplot(cor(diab_no_output), order = "hclust", tl.col = "black", tl.cex = 1)
```

### Actual FA

MLE model:
```{r}
modelo1 <- fa(poly_cor,
  nfactors = 3,
  rotate = "none",
  fm = "mle"
)
```
Minimum residual model:
```{r}
modelo2 <- fa(poly_cor,
  nfactors = 3,
  rotate = "none",
  fm = "minres"
)
```
Compare the communalities
```{r }
c1 <- sort(modelo1$communality, decreasing = T)
c2 <- sort(modelo2$communality, decreasing = T)
head(cbind(c1, c2))
```

<!-- TODO: check the name of this -->
Compare the unicities 

```{r }
u1 <- sort(modelo1$uniquenesses, decreasing = T)
u2 <- sort(modelo2$uniquenesses, decreasing = T)
head(cbind(u1, u2))
```

```{r }
scree(poly_cor)
fa.parallel(poly_cor, n.obs = length(diab_no_output[,1]), fa = "fa", fm = "minres")
```

```{r }
modelo_varimax <- fa(poly_cor,
  nfactors = 3, rotate = "varimax",
  fa = "mle"
)

print(modelo_varimax$loadings, cut = 0)
fa.diagram(modelo_varimax)
stats::factanal(diab_no_output, factors = 3, rotation = "none")
```


<!-- f -->
## Multivariante multivariate

<!-- TODO: adapt to our use case -->

### Distribuciones marginales
```{r}
# Representación mediante Histograma de cada variable para cada especie
par(mfcol = c(2, 3))
for (k in 2:4) {
  j0 <- names(datos)[k]
  # br0 <- seq(min(datos[, k]), max(datos[, k]), le = 11)
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$especie)[i]
    x <- datos[datos$especie == i0, j0]
    hist(x, proba = T, col = grey(0.8), main = paste("especie", i0), xlab = j0)
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}
```

### Gráficos QQ-plot
```{r}
# Representación de cuantiles normales de cada variable para cada especie
par(mfrow = c(2, 3))
for (k in 2:4) {
  j0 <- names(datos)[k]
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$especie)[i]
    x <- datos[datos$especie == i0, j0]
    qqnorm(x, main = paste("especie", i0, j0), pch = 19, col = i + 1)
    qqline(x)
  }
}
par(mfrow = c(1, 1))
```

### Normality tests
#### Univariate

We will use the Shapiro-Wilk test for normality.

```{r}
datos_tidy <- reshape2::melt(diab_no_output, value.name = "value")
stats::aggregate(
  formula = value ~ class + variable,
  data = datos_tidy,
  FUN = function(x) {
    shapiro.test(x)$p.value
  }
)
```

#### Multivariate
<!-- TODO -->

<!-- g -->
## Classifier

```{r}
pairs(
  x = diab_no_output[sample(nrow(diab_no_output), 100), ],
  col = c("green", "red")[new_diab$class],
  pch = 19
)
```